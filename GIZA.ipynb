{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BprYDf4J9tM",
        "outputId": "13b24437-63bc-460f-8199-6173138e8a21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finish 4\n",
            "Total Time : 0.3850274085998535\n",
            "finish 8\n",
            "Total Time : 0.5965266227722168\n",
            "finish 12\n",
            "Total Time : 0.6931428909301758\n"
          ]
        }
      ],
      "source": [
        "from pprint import pprint\n",
        "from pandas.core.frame import DataFrame\n",
        "import pandas as pd\n",
        "import json\n",
        "import requests\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from multiprocessing import Pool\n",
        "from multiprocessing import Process\n",
        "# function to use requests.post to make an API call to the subgraph url\n",
        "\n",
        "global df\n",
        "global df_len\n",
        "df = pd.read_csv('minitemp.csv').to_dict()\n",
        "df_len = len(df['id'])\n",
        "global count\n",
        "count= 0\n",
        "\n",
        "def run_query(query):\n",
        "\n",
        "    # endpoint where you are making the request\n",
        "    request = requests.post('https://gateway-arbitrum.network.thegraph.com/api/5736048735d4ddab454e9c3adb00f5f5/subgraphs/id/A3Np3RQbaBA6oKJgiwDJeo5T3zrYfGHPWFYayMwtNDum',\n",
        "                            json={'query': query})\n",
        "    if request.status_code == 200:\n",
        "        return request.json()\n",
        "    else:\n",
        "        raise Exception('Query failed. return code is {}.      {}'.format(request.status_code, query))\n",
        "\n",
        "\n",
        "mint_query_template = '''\n",
        "{\n",
        "  mints(orderBy: timestamp, orderDirection: asc, where:{ pair: \"pair_address\" }) {\n",
        "      amount0\n",
        "      amount1\n",
        "      to\n",
        "      sender\n",
        "      timestamp\n",
        " }\n",
        "}\n",
        "'''\n",
        "\n",
        "swap_query_template = '''\n",
        "{\n",
        "  swaps(orderBy: timestamp, orderDirection: asc, where:{ pair: \"pair_address\" }) {\n",
        "      amount0In\n",
        "      amount0Out\n",
        "      amount1In\n",
        "      amount1Out\n",
        "      to\n",
        "      sender\n",
        "      timestamp\n",
        " }\n",
        "}\n",
        "'''\n",
        "\n",
        "burn_query_template = '''\n",
        "{\n",
        "  burns(orderBy: timestamp, orderDirection: asc, where:{ pair: \"pair_address\" }) {\n",
        "      amount0\n",
        "      amount1\n",
        "      to\n",
        "      sender\n",
        "      timestamp\n",
        " }\n",
        "}\n",
        "'''\n",
        "\n",
        "#############모든 pair 쌍에 대해서 Mint Query 후 결과 저장##############\n",
        "def get_mint_subProcess(pair_address):\n",
        "    try:\n",
        "        query = mint_query_template.replace('pair_address',pair_address)\n",
        "        result = run_query(query)\n",
        "        return {pair_address : result['data']['mints']}\n",
        "    except:\n",
        "        return {pair_address : ['Error Occur']}\n",
        "\n",
        "def get_mint():\n",
        "    file_path = \"./mint.json\"\n",
        "    mint_json = {}\n",
        "    try:\n",
        "      p = Pool(8)\n",
        "      start = time.time()\n",
        "      global count\n",
        "      for ret in p.imap(get_mint_subProcess,df['id'].values()):\n",
        "        count = count+1\n",
        "#        print(\"Got value\",ret,\"Time :\",time.time()-start)\n",
        "        mint_json.update(ret)\n",
        "        if(count % 1000 == 0):\n",
        "          print(\"Process Rate : {}/{} {}%\".format(count,df_len,int((count/df_len)*100)))\n",
        "#          print(\"write file count : \" + str(count))\n",
        "#          with open(file_path,'w') as outfile:\n",
        "#            json.dump(mint_json, outfile, indent=4)\n",
        "\n",
        "      print('finish ' + str(count))\n",
        "      with open(file_path,'w') as outfile:\n",
        "            json.dump(mint_json, outfile, indent=4)\n",
        "      delta_t = time.time() - start\n",
        "      print(\"Total Time :\",delta_t)\n",
        "      p.close()\n",
        "      p.join()\n",
        "      mint_json.clear()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "\n",
        "\n",
        "#############모든 pair 쌍에 대해서 Mint Query 후 결과 저장##############\n",
        "def get_swap_subProcess(pair_address):\n",
        "    try:\n",
        "        query = swap_query_template.replace('pair_address',pair_address)\n",
        "        result = run_query(query)\n",
        "        return {pair_address : result['data']['swaps']}\n",
        "    except:\n",
        "        return {pair_address : ['Error Occur']}\n",
        "\n",
        "def get_swap():\n",
        "    file_path = \"./swap.json\"\n",
        "    swap_json = {}\n",
        "    try:\n",
        "        p = Pool(8)\n",
        "        start = time.time()\n",
        "        global count\n",
        "        for ret in p.imap(get_swap_subProcess,df['id'].values()):\n",
        "            count = count+1\n",
        "            swap_json.update(ret)\n",
        "            if(count % 1000 == 0):\n",
        "                print(\"Process Rate : {}/{} {}%\".format(count,df_len,int((count/df_len)*100)))\n",
        " #               print(\"write file count : \" + str(count))\n",
        " #               with open(file_path,'w') as outfile:\n",
        " #                   json.dump(swap_json, outfile, indent=4)\n",
        "\n",
        "        p.close()\n",
        "        p.join()\n",
        "        print('finish ' + str(count))\n",
        "        with open(file_path,'w') as outfile:\n",
        "            json.dump(swap_json, outfile, indent=4)\n",
        "        delta_t = time.time() - start\n",
        "        print(\"Total Time :\",delta_t)\n",
        "        swap_json.clear()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "\n",
        "#############모든 pair 쌍에 대해서 Burn Query 후 결과 저장##############\n",
        "def get_burn_subProcess(pair_address):\n",
        "    try:\n",
        "        query = burn_query_template.replace('pair_address',pair_address)\n",
        "        result = run_query(query)\n",
        "        return {pair_address : result['data']['burns']}\n",
        "    except:\n",
        "        return {pair_address : ['Error Occur']}\n",
        "\n",
        "def get_burn():\n",
        "    file_path = \"./burn.json\"\n",
        "    burn_json = {}\n",
        "    try:\n",
        "        p = Pool(8)\n",
        "        start = time.time()\n",
        "        global count\n",
        "        for ret in p.imap(get_burn_subProcess,df['id'].values()):\n",
        "            count = count+1\n",
        "            burn_json.update(ret)\n",
        "            if(count % 1000 == 0):\n",
        "                print(\"Process Rate : {}/{} {}%\".format(count,df_len,int((count/df_len)*100)))\n",
        "#                print(\"write file count : \" + str(count))\n",
        "#                with open(file_path,'w') as outfile:\n",
        "#                    json.dump(burn_json, outfile, indent=4)\n",
        "\n",
        "        p.close()\n",
        "        p.join()\n",
        "        print('finish ' + str(count))\n",
        "        with open(file_path,'w') as outfile:\n",
        "            json.dump(burn_json, outfile, indent=4)\n",
        "        delta_t = time.time() - start\n",
        "        print(\"Total Time :\",delta_t)\n",
        "        burn_json.clear()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "\n",
        "\n",
        "if __name__=='__main__':\n",
        "    get_mint()\n",
        "    get_burn()\n",
        "    get_swap()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from pprint import pprint\n",
        "# from pandas.core.frame import DataFrame\n",
        "# import pandas as pd\n",
        "# import json\n",
        "# import requests\n",
        "# import time\n",
        "# from tqdm import tqdm\n",
        "# from multiprocessing import Pool\n",
        "# from multiprocessing import Process\n",
        "# # function to use requests.post to make an API call to the subgraph url\n",
        "\n",
        "# global df\n",
        "# global df_len\n",
        "# df = pd.read_csv('minitemp.csv').to_dict()\n",
        "# df_len = len(df['id'])\n",
        "# global count\n",
        "# count= 0\n",
        "\n",
        "def run_query(query):\n",
        "\n",
        "    # endpoint where you are making the request\n",
        "    request = requests.post('https://gateway-arbitrum.network.thegraph.com/api/5736048735d4ddab454e9c3adb00f5f5/subgraphs/id/A3Np3RQbaBA6oKJgiwDJeo5T3zrYfGHPWFYayMwtNDum',\n",
        "                            json={'query': query})\n",
        "    if request.status_code == 200:\n",
        "        return request.json()\n",
        "    else:\n",
        "        raise Exception('Query failed. return code is {}.      {}'.format(request.status_code, query))\n",
        "\n",
        "\n",
        "mint_query_template = '''\n",
        "{\n",
        "  mints(orderBy: timestamp, orderDirection: desc, where:{ pair: \"pair_address\" }) {\n",
        "      amount0\n",
        "      amount1\n",
        "      to\n",
        "      sender\n",
        "      timestamp\n",
        " }\n",
        "}\n",
        "'''\n",
        "\n",
        "swap_query_template = '''\n",
        "{\n",
        "  swaps(orderBy: timestamp, orderDirection: desc, where:{ pair: \"pair_address\" }) {\n",
        "      amount0In\n",
        "      amount0Out\n",
        "      amount1In\n",
        "      amount1Out\n",
        "      to\n",
        "      sender\n",
        "      timestamp\n",
        " }\n",
        "}\n",
        "'''\n",
        "\n",
        "burn_query_template = '''\n",
        "{\n",
        "  burns(orderBy: timestamp, orderDirection: desc, where:{ pair: \"pair_address\" }) {\n",
        "      amount0\n",
        "      amount1\n",
        "      to\n",
        "      sender\n",
        "      timestamp\n",
        " }\n",
        "}\n",
        "'''\n",
        "\n",
        "#############모든 pair 쌍에 대해서 Mint Query 후 결과 저장##############\n",
        "def get_mint_subProcess(pair_address):\n",
        "    try:\n",
        "        query = mint_query_template.replace('pair_address',pair_address)\n",
        "        result = run_query(query)\n",
        "        return {pair_address : result['data']['mints']}\n",
        "    except:\n",
        "        return {pair_address : ['Error Occur']}\n",
        "\n",
        "def get_mint():\n",
        "    file_path = \"./mint.json\"\n",
        "    mint_json = {}\n",
        "    try:\n",
        "      p = Pool(24)\n",
        "      start = time.time()\n",
        "      global count\n",
        "      for ret in p.imap(get_mint_subProcess,df['id'].values()):\n",
        "        count = count+1\n",
        "#        print(\"Got value\",ret,\"Time :\",time.time()-start)\n",
        "        mint_json.update(ret)\n",
        "        if(count % 500 == 0):\n",
        "          print(\"Process Rate : {}/{} {}%\".format(count,df_len,int((count/df_len)*100)))\n",
        "          print(\"write file count : \" + str(count))\n",
        "          with open(file_path,'w') as outfile:\n",
        "            json.dump(mint_json, outfile, indent=4)\n",
        "\n",
        "      print('finish ' + str(count))\n",
        "      with open(file_path,'w') as outfile:\n",
        "            json.dump(mint_json, outfile, indent=4)\n",
        "      delta_t = time.time() - start\n",
        "      print(\"Total Time :\",delta_t)\n",
        "      p.close()\n",
        "      p.join()\n",
        "      mint_json.clear()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "\n",
        "\n",
        "#############모든 pair 쌍에 대해서 Mint Query 후 결과 저장##############\n",
        "def get_swap_subProcess(pair_address):\n",
        "    try:\n",
        "        query = swap_query_template.replace('pair_address',pair_address)\n",
        "        result = run_query(query)\n",
        "        return {pair_address : result['data']['swaps']}\n",
        "    except:\n",
        "        return {pair_address : ['Error Occur']}\n",
        "\n",
        "def get_swap():\n",
        "    file_path = \"./swap.json\"\n",
        "    swap_json = {}\n",
        "    try:\n",
        "        p = Pool(8)\n",
        "        start = time.time()\n",
        "        global count\n",
        "        for ret in p.imap(get_swap_subProcess,df['id'].values()):\n",
        "            count = count+1\n",
        "            swap_json.update(ret)\n",
        "            if(count % 500 == 0):\n",
        "                print(\"Process Rate : {}/{} {}%\".format(count,df_len,int((count/df_len)*100)))\n",
        "                print(\"write file count : \" + str(count))\n",
        "                with open(file_path,'w') as outfile:\n",
        "                    json.dump(swap_json, outfile, indent=4)\n",
        "\n",
        "        p.close()\n",
        "        p.join()\n",
        "        print('finish ' + str(count))\n",
        "        with open(file_path,'w') as outfile:\n",
        "            json.dump(swap_json, outfile, indent=4)\n",
        "        delta_t = time.time() - start\n",
        "        print(\"Total Time :\",delta_t)\n",
        "        swap_json.clear()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "\n",
        "#############모든 pair 쌍에 대해서 Burn Query 후 결과 저장##############\n",
        "def get_burn_subProcess(pair_address):\n",
        "    try:\n",
        "        query = burn_query_template.replace('pair_address',pair_address)\n",
        "        result = run_query(query)\n",
        "        return {pair_address : result['data']['burns']}\n",
        "    except:\n",
        "        return {pair_address : ['Error Occur']}\n",
        "\n",
        "def get_burn():\n",
        "    file_path = \"./burn.json\"\n",
        "    burn_json = {}\n",
        "    try:\n",
        "        p = Pool(16)\n",
        "        start = time.time()\n",
        "        global count\n",
        "        for ret in p.imap(get_burn_subProcess,df['id'].values()):\n",
        "            count = count+1\n",
        "            burn_json.update(ret)\n",
        "            if(count % 500 == 0):\n",
        "                print(\"Process Rate : {}/{} {}%\".format(count,df_len,int((count/df_len)*100)))\n",
        "                print(\"write file count : \" + str(count))\n",
        "                with open(file_path,'w') as outfile:\n",
        "                    json.dump(burn_json, outfile, indent=4)\n",
        "\n",
        "        p.close()\n",
        "        p.join()\n",
        "        print('finish ' + str(count))\n",
        "        with open(file_path,'w') as outfile:\n",
        "            json.dump(burn_json, outfile, indent=4)\n",
        "        delta_t = time.time() - start\n",
        "        print(\"Total Time :\",delta_t)\n",
        "        burn_json.clear()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def update_mint_json():\n",
        "    try:\n",
        "      p = Pool(24)\n",
        "      start = time.time()\n",
        "      global count\n",
        "      for ret in p.imap(get_mint_subProcess,df['id'].values()):\n",
        "        count = count+1\n",
        "#        print(\"Got value\",ret,\"Time :\",time.time()-start)\n",
        "        mint_json.update(ret)\n",
        "        if(count % 500 == 0):\n",
        "          print(\"Process Rate : {}/{} {}%\".format(count,df_len,int((count/df_len)*100)))\n",
        "          print(\"write file count : \" + str(count))\n",
        "          with open(file_path,'w') as outfile:\n",
        "            json.dump(mint_json, outfile, indent=4)\n",
        "\n",
        "      print('finish ' + str(count))\n",
        "      with open(file_path,'w') as outfile:\n",
        "            json.dump(mint_json, outfile, indent=4)\n",
        "      delta_t = time.time() - start\n",
        "      print(\"Total Time :\",delta_t)\n",
        "      p.close()\n",
        "      p.join()\n",
        "      mint_json.clear()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "if __name__=='__main__':\n",
        "   get_mint()\n",
        "   get_burn()\n",
        "   get_swap()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNu2LnmIL4G_",
        "outputId": "8b8636e9-1757-49de-dd49-a62f2e06f337"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finish 16\n",
            "Total Time : 0.38915109634399414\n",
            "finish 20\n",
            "Total Time : 0.48694491386413574\n",
            "finish 24\n",
            "Total Time : 0.4972507953643799\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.read_csv('minitemp.csv')\n",
        "df1.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "AdiaJ8a6NE4H",
        "outputId": "4453ea7d-e31f-4a4d-a22e-3e90df6bb4c5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   createdAtBlockNumber createdAtTimestamp  \\\n",
              "0              20006534         02-06-2024   \n",
              "1              20006517         02-06-2024   \n",
              "2              20006486         02-06-2024   \n",
              "3              20006486         02-06-2024   \n",
              "\n",
              "                                           id      reserve0      reserve1  \\\n",
              "0  0xc5494572bb74b5dc10e02cbcd5601dc8c529184b  3.982222e+08  1.186498e+00   \n",
              "1  0x1408516701d1d3dec4c1461c19512b2ae7438cea  2.937388e+11  1.907053e+00   \n",
              "2  0xb9a492b90d208ced3c4e53af9601499d05bdcbc3  2.028160e-11  1.000000e-18   \n",
              "3  0x41a0d92e89918581032880fa0698256cd24401e4  1.975682e+07  5.626379e+00   \n",
              "\n",
              "     reserveETH    reserveUSD   totalSupply  txCount     reserve00  ...  \\\n",
              "0  1.186498e+00  4.477622e+03  21730.674673       16  3.982222e+08  ...   \n",
              "1  3.814106e+00  1.439432e+04     23.641066       25  2.937388e+11  ...   \n",
              "2  1.000000e-18  3.700000e-15      0.000000       13  2.028160e-11  ...   \n",
              "3  1.125276e+01  4.246587e+04      0.330387      181  1.975682e+07  ...   \n",
              "\n",
              "                                   token00.id token00.name token00.symbol  \\\n",
              "0  0x87d831af790976dc00ff6b42b25bf46506c8ce90        PONKE          PONKE   \n",
              "1  0x0751b242b5e44ae58b963c5d1ea048e7794280ae    Rubin GPU          RUBIN   \n",
              "2  0x9cea2c26bcefb5e4d0e034420c4dd22655cc59fc        Pe Pe           PEPE   \n",
              "3  0x57fe9b84dd8ab52a3944cd05b5001a0bb5799fdb    brettCoin      brettcoin   \n",
              "\n",
              "  token00.totalLiquidity  token00.txCount  \\\n",
              "0           3.982222e+08               16   \n",
              "1           2.937388e+11               25   \n",
              "2           2.028160e-11               13   \n",
              "3           1.975682e+07              181   \n",
              "\n",
              "                                   token11.id   token11.name token11.symbol  \\\n",
              "0  0xc02aaa39b223fe8d0a0e5c4f27ead9083c756cc2  Wrapped Ether           WETH   \n",
              "1  0xc02aaa39b223fe8d0a0e5c4f27ead9083c756cc2  Wrapped Ether           WETH   \n",
              "2  0xc02aaa39b223fe8d0a0e5c4f27ead9083c756cc2  Wrapped Ether           WETH   \n",
              "3  0xc02aaa39b223fe8d0a0e5c4f27ead9083c756cc2  Wrapped Ether           WETH   \n",
              "\n",
              "  token11.totalLiquidity  token11.txCount  \n",
              "0          293870.012682        168079953  \n",
              "1          293870.012682        168079953  \n",
              "2          293870.012682        168079953  \n",
              "3          293870.012682        168079953  \n",
              "\n",
              "[4 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-879dd9f9-3e22-49ab-8d47-4ff23a6d387b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>createdAtBlockNumber</th>\n",
              "      <th>createdAtTimestamp</th>\n",
              "      <th>id</th>\n",
              "      <th>reserve0</th>\n",
              "      <th>reserve1</th>\n",
              "      <th>reserveETH</th>\n",
              "      <th>reserveUSD</th>\n",
              "      <th>totalSupply</th>\n",
              "      <th>txCount</th>\n",
              "      <th>reserve00</th>\n",
              "      <th>...</th>\n",
              "      <th>token00.id</th>\n",
              "      <th>token00.name</th>\n",
              "      <th>token00.symbol</th>\n",
              "      <th>token00.totalLiquidity</th>\n",
              "      <th>token00.txCount</th>\n",
              "      <th>token11.id</th>\n",
              "      <th>token11.name</th>\n",
              "      <th>token11.symbol</th>\n",
              "      <th>token11.totalLiquidity</th>\n",
              "      <th>token11.txCount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20006534</td>\n",
              "      <td>02-06-2024</td>\n",
              "      <td>0xc5494572bb74b5dc10e02cbcd5601dc8c529184b</td>\n",
              "      <td>3.982222e+08</td>\n",
              "      <td>1.186498e+00</td>\n",
              "      <td>1.186498e+00</td>\n",
              "      <td>4.477622e+03</td>\n",
              "      <td>21730.674673</td>\n",
              "      <td>16</td>\n",
              "      <td>3.982222e+08</td>\n",
              "      <td>...</td>\n",
              "      <td>0x87d831af790976dc00ff6b42b25bf46506c8ce90</td>\n",
              "      <td>PONKE</td>\n",
              "      <td>PONKE</td>\n",
              "      <td>3.982222e+08</td>\n",
              "      <td>16</td>\n",
              "      <td>0xc02aaa39b223fe8d0a0e5c4f27ead9083c756cc2</td>\n",
              "      <td>Wrapped Ether</td>\n",
              "      <td>WETH</td>\n",
              "      <td>293870.012682</td>\n",
              "      <td>168079953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20006517</td>\n",
              "      <td>02-06-2024</td>\n",
              "      <td>0x1408516701d1d3dec4c1461c19512b2ae7438cea</td>\n",
              "      <td>2.937388e+11</td>\n",
              "      <td>1.907053e+00</td>\n",
              "      <td>3.814106e+00</td>\n",
              "      <td>1.439432e+04</td>\n",
              "      <td>23.641066</td>\n",
              "      <td>25</td>\n",
              "      <td>2.937388e+11</td>\n",
              "      <td>...</td>\n",
              "      <td>0x0751b242b5e44ae58b963c5d1ea048e7794280ae</td>\n",
              "      <td>Rubin GPU</td>\n",
              "      <td>RUBIN</td>\n",
              "      <td>2.937388e+11</td>\n",
              "      <td>25</td>\n",
              "      <td>0xc02aaa39b223fe8d0a0e5c4f27ead9083c756cc2</td>\n",
              "      <td>Wrapped Ether</td>\n",
              "      <td>WETH</td>\n",
              "      <td>293870.012682</td>\n",
              "      <td>168079953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20006486</td>\n",
              "      <td>02-06-2024</td>\n",
              "      <td>0xb9a492b90d208ced3c4e53af9601499d05bdcbc3</td>\n",
              "      <td>2.028160e-11</td>\n",
              "      <td>1.000000e-18</td>\n",
              "      <td>1.000000e-18</td>\n",
              "      <td>3.700000e-15</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>13</td>\n",
              "      <td>2.028160e-11</td>\n",
              "      <td>...</td>\n",
              "      <td>0x9cea2c26bcefb5e4d0e034420c4dd22655cc59fc</td>\n",
              "      <td>Pe Pe</td>\n",
              "      <td>PEPE</td>\n",
              "      <td>2.028160e-11</td>\n",
              "      <td>13</td>\n",
              "      <td>0xc02aaa39b223fe8d0a0e5c4f27ead9083c756cc2</td>\n",
              "      <td>Wrapped Ether</td>\n",
              "      <td>WETH</td>\n",
              "      <td>293870.012682</td>\n",
              "      <td>168079953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20006486</td>\n",
              "      <td>02-06-2024</td>\n",
              "      <td>0x41a0d92e89918581032880fa0698256cd24401e4</td>\n",
              "      <td>1.975682e+07</td>\n",
              "      <td>5.626379e+00</td>\n",
              "      <td>1.125276e+01</td>\n",
              "      <td>4.246587e+04</td>\n",
              "      <td>0.330387</td>\n",
              "      <td>181</td>\n",
              "      <td>1.975682e+07</td>\n",
              "      <td>...</td>\n",
              "      <td>0x57fe9b84dd8ab52a3944cd05b5001a0bb5799fdb</td>\n",
              "      <td>brettCoin</td>\n",
              "      <td>brettcoin</td>\n",
              "      <td>1.975682e+07</td>\n",
              "      <td>181</td>\n",
              "      <td>0xc02aaa39b223fe8d0a0e5c4f27ead9083c756cc2</td>\n",
              "      <td>Wrapped Ether</td>\n",
              "      <td>WETH</td>\n",
              "      <td>293870.012682</td>\n",
              "      <td>168079953</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4 rows × 31 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-879dd9f9-3e22-49ab-8d47-4ff23a6d387b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-879dd9f9-3e22-49ab-8d47-4ff23a6d387b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-879dd9f9-3e22-49ab-8d47-4ff23a6d387b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-eb2240e0-e05a-4153-8dd7-0a0a1ef40c87\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-eb2240e0-e05a-4153-8dd7-0a0a1ef40c87')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-eb2240e0-e05a-4153-8dd7-0a0a1ef40c87 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df1"
            }
          },
          "metadata": {},
          "execution_count": 5
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Total number of columns (31) exceeds max_columns (20) limiting to first (20) columns.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kydt4fI0NGCl",
        "outputId": "7c6016f3-4cb8-49db-8c10-765124a1a83b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4 entries, 0 to 3\n",
            "Data columns (total 31 columns):\n",
            " #   Column                  Non-Null Count  Dtype  \n",
            "---  ------                  --------------  -----  \n",
            " 0   createdAtBlockNumber    4 non-null      int64  \n",
            " 1   createdAtTimestamp      4 non-null      object \n",
            " 2   id                      4 non-null      object \n",
            " 3   reserve0                4 non-null      float64\n",
            " 4   reserve1                4 non-null      float64\n",
            " 5   reserveETH              4 non-null      float64\n",
            " 6   reserveUSD              4 non-null      float64\n",
            " 7   totalSupply             4 non-null      float64\n",
            " 8   txCount                 4 non-null      int64  \n",
            " 9   reserve00               4 non-null      float64\n",
            " 10  reserve11               4 non-null      float64\n",
            " 11  token0.id               4 non-null      object \n",
            " 12  token0.name             4 non-null      object \n",
            " 13  token0.symbol           4 non-null      object \n",
            " 14  token0.totalLiquidity   4 non-null      float64\n",
            " 15  token0.txCount          4 non-null      int64  \n",
            " 16  token1.id               4 non-null      object \n",
            " 17  token1.name             4 non-null      object \n",
            " 18  token1.symbol           4 non-null      object \n",
            " 19  token1.totalLiquidity   4 non-null      float64\n",
            " 20  token1.txCount          4 non-null      int64  \n",
            " 21  token00.id              4 non-null      object \n",
            " 22  token00.name            4 non-null      object \n",
            " 23  token00.symbol          4 non-null      object \n",
            " 24  token00.totalLiquidity  4 non-null      float64\n",
            " 25  token00.txCount         4 non-null      int64  \n",
            " 26  token11.id              4 non-null      object \n",
            " 27  token11.name            4 non-null      object \n",
            " 28  token11.symbol          4 non-null      object \n",
            " 29  token11.totalLiquidity  4 non-null      float64\n",
            " 30  token11.txCount         4 non-null      int64  \n",
            "dtypes: float64(11), int64(6), object(14)\n",
            "memory usage: 1.1+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initial Liquidity\n"
      ],
      "metadata": {
        "id": "Ti2DyUBlPekT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('./mint.json', 'r') as f:\n",
        "    mint_json = json.load(f)\n",
        "\n",
        "len(mint_json)\n",
        "datas = pd.read_csv('minitemp.csv',encoding='utf-8-sig').to_dict('records')\n",
        "\n",
        "\n",
        "for data in datas:\n",
        "    pair_id = data['id']\n",
        "\n",
        "    if(len(mint_json[pair_id]) == 0 ):     #Mint 정보가 없는 pair는 초기 Liquidity를 0으로 한다.\n",
        "        data['initial_Liquidity_ETH'] = 0\n",
        "        data['initial_Liquidity_token'] = 0\n",
        "        continue\n",
        "\n",
        "\n",
        "    if(data['token0.symbol'] == 'WETH'):\n",
        "        initial_Liquidity_ETH = mint_json[pair_id][0]['amount0']\n",
        "        initial_Liquidity_token = mint_json[pair_id][0]['amount1']\n",
        "    else:\n",
        "        initial_Liquidity_ETH = mint_json[pair_id][0]['amount1']\n",
        "        initial_Liquidity_token = mint_json[pair_id][0]['amount0']\n",
        "\n",
        "    data['initial_Liquidity_ETH'] = initial_Liquidity_ETH\n",
        "    data['initial_Liquidity_token'] = initial_Liquidity_token\n",
        "\n",
        "\n",
        "for i in range(4):\n",
        "    print(datas[i]['initial_Liquidity_token'])\n",
        "\n",
        "DataFrame(datas).to_csv('minitemp1.csv',encoding='utf-8-sig')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yr2AJLH7NuJL",
        "outputId": "8ac8d9fa-fe28-457f-f83a-d363f0c9a7a5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "472222221.75\n",
            "558900000000\n",
            "720000000\n",
            "109155847.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = pd.read_csv('minitemp1.csv')\n",
        "df2.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uClskr9UOXSr",
        "outputId": "cb3b77db-8453-4f89-a469-d0236b224ee7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4 entries, 0 to 3\n",
            "Data columns (total 34 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   Unnamed: 0               4 non-null      int64  \n",
            " 1   createdAtBlockNumber     4 non-null      int64  \n",
            " 2   createdAtTimestamp       4 non-null      object \n",
            " 3   id                       4 non-null      object \n",
            " 4   reserve0                 4 non-null      float64\n",
            " 5   reserve1                 4 non-null      float64\n",
            " 6   reserveETH               4 non-null      float64\n",
            " 7   reserveUSD               4 non-null      float64\n",
            " 8   totalSupply              4 non-null      float64\n",
            " 9   txCount                  4 non-null      int64  \n",
            " 10  reserve00                4 non-null      float64\n",
            " 11  reserve11                4 non-null      float64\n",
            " 12  token0.id                4 non-null      object \n",
            " 13  token0.name              4 non-null      object \n",
            " 14  token0.symbol            4 non-null      object \n",
            " 15  token0.totalLiquidity    4 non-null      float64\n",
            " 16  token0.txCount           4 non-null      int64  \n",
            " 17  token1.id                4 non-null      object \n",
            " 18  token1.name              4 non-null      object \n",
            " 19  token1.symbol            4 non-null      object \n",
            " 20  token1.totalLiquidity    4 non-null      float64\n",
            " 21  token1.txCount           4 non-null      int64  \n",
            " 22  token00.id               4 non-null      object \n",
            " 23  token00.name             4 non-null      object \n",
            " 24  token00.symbol           4 non-null      object \n",
            " 25  token00.totalLiquidity   4 non-null      float64\n",
            " 26  token00.txCount          4 non-null      int64  \n",
            " 27  token11.id               4 non-null      object \n",
            " 28  token11.name             4 non-null      object \n",
            " 29  token11.symbol           4 non-null      object \n",
            " 30  token11.totalLiquidity   4 non-null      float64\n",
            " 31  token11.txCount          4 non-null      int64  \n",
            " 32  initial_Liquidity_ETH    4 non-null      int64  \n",
            " 33  initial_Liquidity_token  4 non-null      float64\n",
            "dtypes: float64(12), int64(8), object(14)\n",
            "memory usage: 1.2+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfmain = pd.read_csv('main_pair.csv')"
      ],
      "metadata": {
        "id": "RrnfDcBEPNx-"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfmain.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgKCfnnEa7KD",
        "outputId": "f18dbfe1-9fcb-4d07-eac4-da14b4a14c6a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 316707 entries, 0 to 316706\n",
            "Data columns (total 31 columns):\n",
            " #   Column                  Non-Null Count   Dtype  \n",
            "---  ------                  --------------   -----  \n",
            " 0   createdAtBlockNumber    316707 non-null  int64  \n",
            " 1   createdAtTimestamp      316707 non-null  object \n",
            " 2   id                      316707 non-null  object \n",
            " 3   reserve0                316707 non-null  float64\n",
            " 4   reserve1                316707 non-null  float64\n",
            " 5   reserveETH              316707 non-null  float64\n",
            " 6   reserveUSD              316707 non-null  float64\n",
            " 7   totalSupply             316707 non-null  float64\n",
            " 8   txCount                 316707 non-null  int64  \n",
            " 9   reserve00               316707 non-null  float64\n",
            " 10  reserve11               316707 non-null  float64\n",
            " 11  token0.id               316707 non-null  object \n",
            " 12  token0.name             316654 non-null  object \n",
            " 13  token0.symbol           316627 non-null  object \n",
            " 14  token0.totalLiquidity   316707 non-null  float64\n",
            " 15  token0.txCount          316707 non-null  int64  \n",
            " 16  token1.id               316707 non-null  object \n",
            " 17  token1.name             316695 non-null  object \n",
            " 18  token1.symbol           316687 non-null  object \n",
            " 19  token1.totalLiquidity   316707 non-null  float64\n",
            " 20  token1.txCount          316707 non-null  int64  \n",
            " 21  token00.id              316707 non-null  object \n",
            " 22  token00.name            316642 non-null  object \n",
            " 23  token00.symbol          316607 non-null  object \n",
            " 24  token00.totalLiquidity  316707 non-null  float64\n",
            " 25  token00.txCount         316707 non-null  int64  \n",
            " 26  token11.id              316707 non-null  object \n",
            " 27  token11.name            316707 non-null  object \n",
            " 28  token11.symbol          316707 non-null  object \n",
            " 29  token11.totalLiquidity  316707 non-null  float64\n",
            " 30  token11.txCount         316707 non-null  int64  \n",
            "dtypes: float64(11), int64(6), object(14)\n",
            "memory usage: 74.9+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MAIN WORK\n"
      ],
      "metadata": {
        "id": "9Lz9RPkLbk4u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Graphlib"
      ],
      "metadata": {
        "id": "qZ_hQiP0btjb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "mint_query_template = '''\n",
        "{\n",
        "  mints(first: 1000, orderBy: timestamp, orderDirection: asc, where:{ pair: \"%s\" , timestamp_gt:%s  }) {\n",
        "      amount0\n",
        "      amount1\n",
        "      to\n",
        "      sender\n",
        "      timestamp\n",
        " }\n",
        "}\n",
        "'''\n",
        "\n",
        "swap_query_template = '''\n",
        "{\n",
        "  swaps(first: 1000, orderBy: timestamp, orderDirection: asc, where:{ pair: \"%s\" , timestamp_gt:%s }) {\n",
        "      amount0In\n",
        "      amount0Out\n",
        "      amount1In\n",
        "      amount1Out\n",
        "      to\n",
        "      sender\n",
        "      timestamp\n",
        " }\n",
        "}\n",
        "'''\n",
        "\n",
        "\n",
        "burn_query_template = '''\n",
        "{\n",
        "  burns(first: 1000, orderBy: timestamp, orderDirection: asc, where:{ pair: \"%s\" , timestamp_gt:%s }) {\n",
        "      amount0\n",
        "\n",
        "      amount1\n",
        "      to\n",
        "      sender\n",
        "      timestamp\n",
        " }\n",
        "}\n",
        "'''\n",
        "\n",
        "\n",
        "def run_query(query):\n",
        "\n",
        "    # endpoint where you are making the request\n",
        "    request = requests.post('https://gateway-arbitrum.network.thegraph.com/api/5736048735d4ddab454e9c3adb00f5f5/subgraphs/id/A3Np3RQbaBA6oKJgiwDJeo5T3zrYfGHPWFYayMwtNDum',\n",
        "                            json={'query': query})\n",
        "    if request.status_code == 200:\n",
        "        return request.json()\n",
        "    else:\n",
        "        raise Exception('Query failed. return code is {}.      {}'.format(request.status_code, query))\n",
        "\n",
        "def call_theGraph_mint(pair_id):\n",
        "    mint_array = []\n",
        "    timestamp = 0\n",
        "    try:\n",
        "      while(True):\n",
        "        query = mint_query_template % (pair_id,timestamp)\n",
        "        result = run_query(query)\n",
        "\n",
        "        if(len(result['data']['mints']) < 1000):\n",
        "          mint_array.extend(result['data']['mints'])\n",
        "          break\n",
        "\n",
        "        mint_array.extend(result['data']['mints'])\n",
        "        timestamp = result['data']['mints'][999]['timestamp']\n",
        "    except Exception as e:\n",
        "      print('error in theGraph_swap')\n",
        "      print(e)\n",
        "\n",
        "    return mint_array\n",
        "\n",
        "def call_theGraph_swap(pair_id):\n",
        "    swap_array = []\n",
        "    timestamp = 0\n",
        "    try:\n",
        "      while(True):\n",
        "        query = swap_query_template % (pair_id,timestamp)\n",
        "        result = run_query(query)\n",
        "\n",
        "        if(len(result['data']['swaps']) < 1000): # 1000개 미만이니까 끝낸다.\n",
        "          swap_array.extend(result['data']['swaps'])\n",
        "          break\n",
        "\n",
        "        swap_array.extend(result['data']['swaps'])\n",
        "        timestamp = result['data']['swaps'][999]['timestamp']\n",
        "    except Exception as e:\n",
        "      print('error in theGraph_swap')\n",
        "      print(e)\n",
        "\n",
        "    return swap_array\n",
        "\n",
        "def call_theGraph_burn(pair_id):\n",
        "    burn_array = []\n",
        "    timestamp = 0\n",
        "    try:\n",
        "      while(True):\n",
        "        query = burn_query_template % (pair_id,timestamp)\n",
        "        result = run_query(query)\n",
        "\n",
        "        if(len(result['data']['burns']) < 1000): # 1000개 미만이니까 끝낸다.\n",
        "          burn_array.extend(result['data']['burns'])\n",
        "          break\n",
        "\n",
        "        burn_array.extend(result['data']['burns'])\n",
        "        timestamp = result['data']['burns'][999]['timestamp']\n",
        "    except Exception as e:\n",
        "      print('error in theGraph_burn')\n",
        "      print(e)\n",
        "\n",
        "    return burn_array"
      ],
      "metadata": {
        "id": "I96J30Hsbj0p"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FeatureLIB\n"
      ],
      "metadata": {
        "id": "U8PGP4AiiQcW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from decimal import Decimal\n",
        "import decimal\n",
        "from math import sqrt\n",
        "from pprint import pprint as pp\n",
        "\n",
        "def get_initial_Liquidity(token0_symbol,mint_data_transaction):\n",
        "  if(token0_symbol == 'WETH'):\n",
        "      initial_Liquidity_ETH = mint_data_transaction[0]['amount0']\n",
        "      initial_Liquidity_token = mint_data_transaction[0]['amount1']\n",
        "  else:\n",
        "      initial_Liquidity_ETH = mint_data_transaction[0]['amount1']\n",
        "      initial_Liquidity_token = mint_data_transaction[0]['amount0']\n",
        "\n",
        "  return initial_Liquidity_ETH,initial_Liquidity_token\n",
        "\n",
        "def get_initial_Liquidity_token(mint_data_transaction,index):\n",
        "  if(index == 1):\n",
        "    return Decimal(mint_data_transaction[0]['amount1'])\n",
        "  else:\n",
        "    return Decimal(mint_data_transaction[0]['amount0'])\n",
        "\n",
        "def get_mint_mean_period(mint_data_transaction,initial_timestamp):\n",
        "    count = len(mint_data_transaction)\n",
        "    if(count == 0):\n",
        "      return 0\n",
        "    mint_time_add = 0\n",
        "    for transaction in mint_data_transaction:\n",
        "      mint_time_add = mint_time_add + int(transaction['timestamp']) - initial_timestamp\n",
        "    return mint_time_add / count\n",
        "\n",
        "def get_swap_mean_period(swap_data_transaction,initial_timestamp):\n",
        "    count = len(swap_data_transaction)\n",
        "    if(count == 0):\n",
        "      return 0\n",
        "    swap_time_add = 0\n",
        "    for transaction in swap_data_transaction:\n",
        "      swap_time_add = swap_time_add +  int(transaction['timestamp']) - initial_timestamp\n",
        "    return swap_time_add / count\n",
        "\n",
        "def get_burn_mean_period(burn_data_transaction,initial_timestamp):\n",
        "    count = len(burn_data_transaction)\n",
        "    if(count == 0):\n",
        "      return 0\n",
        "    burn_time_add = 0\n",
        "    for transaction in burn_data_transaction:\n",
        "      burn_time_add = burn_time_add + int(transaction['timestamp']) - initial_timestamp\n",
        "    return burn_time_add / count\n",
        "\n",
        "def swap_IO_rate(swap_data_transaction,index):\n",
        "  swapIn = 0\n",
        "  swapOut = 0\n",
        "  if(index == 1):\n",
        "    for data in swap_data_transaction:\n",
        "      if(data['amount0In'] == '0'):\n",
        "        swapOut = swapOut + 1\n",
        "      else:\n",
        "        swapIn = swapIn + 1\n",
        "  else:\n",
        "    for data in swap_data_transaction:\n",
        "      if(data['amount1In'] == '0'):\n",
        "        swapOut = swapOut + 1\n",
        "      else:\n",
        "        swapIn = swapIn +1\n",
        "\n",
        "  return swapIn,swapOut\n",
        "\n",
        "def get_last_timestamp(mint_data_transaction,swap_data_transaction,burn_data_transaction):\n",
        "\n",
        "  swap_len = len(swap_data_transaction)\n",
        "  burn_len = len(burn_data_transaction)\n",
        "  #Case 1 Swap / Burn\n",
        "  if(swap_len == 0 and burn_len == 0):\n",
        "    return int(mint_data_transaction[-1]['timestamp'])\n",
        "  #Case 2 Swap_transaction\n",
        "  if(swap_len == 0):\n",
        "    return int(max(mint_data_transaction[-1]['timestamp'],burn_data_transaction[-1]['timestamp']))\n",
        "  #Case 3 Burn Transaction\n",
        "  if(burn_len == 0):\n",
        "    return int(max(mint_data_transaction[-1]['timestamp'],swap_data_transaction[-1]['timestamp']))\n",
        "  #Case 4\n",
        "  return int(max(mint_data_transaction[-1]['timestamp'],burn_data_transaction[-1]['timestamp'],swap_data_transaction[-1]['timestamp']))\n",
        "\n",
        "def get_swap_amount(swap_data_transaction,j,eth_amountIn,eth_amountOut):\n",
        "  if(swap_data_transaction[j][eth_amountIn] == '0'): #amountIn\n",
        "    return Decimal(swap_data_transaction[j][eth_amountOut]) * (-1)\n",
        "  else:\n",
        "    return Decimal(swap_data_transaction[j][eth_amountIn])\n",
        "\n",
        "def get_swap_token(swap_data_transaction,j,index):\n",
        "  if(index == 1):\n",
        "    swap_amount = Decimal(swap_data_transaction[j]['amount1In'])\n",
        "    swap_amount = Decimal(swap_amount) - Decimal(swap_data_transaction[j]['amount1Out'])\n",
        "  else:\n",
        "    swap_amount = Decimal(swap_data_transaction[j]['amount0In'])\n",
        "    swap_amount = Decimal(swap_amount) - Decimal(swap_data_transaction[j]['amount0Out'])\n",
        "\n",
        "  return swap_amount\n",
        "\n",
        "def get_timestamp(data_transaction,index):\n",
        "  try:\n",
        "    return data_transaction[index]['timestamp']\n",
        "  except:\n",
        "    return '99999999999'\n",
        "\n",
        "def check_rugpull(before_transaction_Eth, current_Eth):\n",
        "  if ( abs(Decimal(current_Eth) / Decimal(before_transaction_Eth)) <= 0.01 ):\n",
        "    if( Decimal(before_transaction_Eth) < 0 or Decimal(current_Eth) < 0):\n",
        "      return False\n",
        "    else:\n",
        "      return True\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "def is_MEV(initial_Liquidity_token, swapIn_token):\n",
        "  if(swapIn_token > initial_Liquidity_token * 5):  #swap rugpull\n",
        "    return False    #얘는 진짜 러그풀인 경우\n",
        "  else:\n",
        "    return True     #MEV RugPull\n",
        "\n",
        "def get_rugpull_timestamp(mint_data_transaction,swap_data_transaction,burn_data_transaction,index):\n",
        "    if(index == 1):\n",
        "      eth_amount = 'amount0'\n",
        "      eth_amountIn = 'amount0In'\n",
        "      eth_amountOut = 'amount0Out'\n",
        "    else:\n",
        "      eth_amount = 'amount1'\n",
        "      eth_amountIn = 'amount1In'\n",
        "      eth_amountOut = 'amount1Out'\n",
        "\n",
        "\n",
        "    swap_count = len(swap_data_transaction)\n",
        "    burn_count = len(burn_data_transaction)\n",
        "\n",
        "\n",
        "\n",
        "    current_Liquidity_Eth = Decimal(mint_data_transaction[0][eth_amount])\n",
        "    initial_Liquidity_token = get_initial_Liquidity_token(mint_data_transaction,index)\n",
        "    i,j,k = 1,0,0\n",
        "\n",
        "    while True:\n",
        "      try:\n",
        "        next_timestamp = min(get_timestamp(mint_data_transaction,i),get_timestamp(burn_data_transaction,k))\n",
        "\n",
        "        while(get_timestamp(swap_data_transaction,j) <= next_timestamp ):\n",
        "          if(get_timestamp(swap_data_transaction,j) == '99999999999'):\n",
        "            break\n",
        "\n",
        "          #\n",
        "          before_transaction_Eth = current_Liquidity_Eth\n",
        "          current_Liquidity_Eth = current_Liquidity_Eth + get_swap_amount(swap_data_transaction,j,eth_amountIn,eth_amountOut)\n",
        "          #print(\"swap {before : %s swap_amount : %s\"%(str(before_transaction_Eth),str(current_Liquidity_Eth-before_transaction_Eth)))\n",
        "\n",
        "          if( check_rugpull(before_transaction_Eth,current_Liquidity_Eth) ):\n",
        "              if( is_MEV(initial_Liquidity_token,get_swap_token(swap_data_transaction,j,index)) == False ):\n",
        "                print(\"swap rugpull : initial token = %s / before Eth = %s / after Eth = %s swapIn_token_amount = %s\"%(initial_Liquidity_token,str(before_transaction_Eth),str(current_Liquidity_Eth),get_swap_token(swap_data_transaction,j,index)))\n",
        "                return get_timestamp(swap_data_transaction,j), Decimal(current_Liquidity_Eth / before_transaction_Eth) -1, True, before_transaction_Eth,current_Liquidity_Eth,'swap',[i,j-1,k]\n",
        "          j = j+1\n",
        "\n",
        "        #mint 인 경우 curruent_Eth 더하는 로직\n",
        "        if(next_timestamp == get_timestamp(mint_data_transaction,i)): #mint가 최소라면, + 한다.\n",
        "          if(next_timestamp == '99999999999'):  #이건 rugpull이 없는 경우\n",
        "            try:\n",
        "                #여기까지 온거면 rugpull이 없는 경우인데 이때 네가지 케이스에 대한 예외케이스를 정의 해야한다.\n",
        "                #Case 1 Swap/Burn이 없는 경우\n",
        "                if(swap_count == 0 and burn_count == 0):\n",
        "                    return mint_data_transaction[-1]['timestamp'],0, False, 0,0,''\n",
        "                #Case 2 Swap이 없는 경우\n",
        "                if(swap_count == 0):\n",
        "                    return max(mint_data_transaction[-1]['timestamp'],burn_data_transaction[-1]['timestamp']),0,False, 0,0,''\n",
        "                #Case 3 Burn이 없는 경우\n",
        "                if(burn_count == 0):\n",
        "                    return max(mint_data_transaction[-1]['timestamp'],swap_data_transaction[-1]['timestamp']),0,False, 0,0,''\n",
        "                #Case 4 Mint/Swap/Burn이 다 있지만, Rugpull이 아닌 경우\n",
        "                return max(mint_data_transaction[-1]['timestamp'],burn_data_transaction[-1]['timestamp'],swap_data_transaction[-1]['timestamp']),0,False, 0,0,''\n",
        "            except:\n",
        "              return 'Error occur',100.0,False,1,1\n",
        "          before_transaction_Eth = current_Liquidity_Eth\n",
        "          current_Liquidity_Eth = current_Liquidity_Eth + Decimal(mint_data_transaction[i][eth_amount])\n",
        "          #print(\"mint {before : %s burn_amount : %s\"%(str(before_transaction_Eth),str(current_Liquidity_Eth-before_transaction_Eth)))\n",
        "          i = i+1\n",
        "\n",
        "        #burn 인 경우 current_Eth 빼는 로직 / 러그풀 타임스탬프 체\n",
        "        else:\n",
        "          before_transaction_Eth = current_Liquidity_Eth\n",
        "          current_Liquidity_Eth = current_Liquidity_Eth - Decimal(burn_data_transaction[k][eth_amount])\n",
        "          #print(\"burn {before : %s burn_amount : %s\"%(str(before_transaction_Eth),str(current_Liquidity_Eth-before_transaction_Eth)))\n",
        "          if(check_rugpull(before_transaction_Eth,current_Liquidity_Eth)):\n",
        "            return get_timestamp(burn_data_transaction,k), Decimal(current_Liquidity_Eth / before_transaction_Eth) -1, True, before_transaction_Eth,current_Liquidity_Eth,'burn'\n",
        "          k = k+1\n",
        "      except Exception as e:\n",
        "        print(e)\n",
        "        print('Critical Error Occur')\n",
        "        return '1',0,False,1,1,'Error'\n",
        "\n",
        "def token_index(data):\n",
        "    if(data['token0.name'] == 'Wrapped Ether'):\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def calc_LPToken_Holders(mint_data_transaction,burn_data_transaction):\n",
        "  #Mint/Burn 트랜잭션을 분석해서, 해당 시점까지의 Holder들의 토큰보유량을 Dictionary로 만들어 놓는다.\n",
        "  zap_list = ['0x343e3a490c9251dc0eaa81da146ba6abe6c78b2d','0x379b4609bdf93b3584cf7b64bc78199cf185f1cd', ]\n",
        "  LP_Holders = {}\n",
        "  for mint in mint_data_transaction:\n",
        "    try:\n",
        "      Holder_address = mint['to'] #to가 Mint를 한 Address\n",
        "      LP_amount = Decimal(mint['liquidity'])\n",
        "      LP_Holders[Holder_address] = LP_Holders[Holder_address] + LP_amount\n",
        "    except:\n",
        "      LP_Holders[Holder_address] = LP_amount\n",
        "\n",
        "  for burn in burn_data_transaction:\n",
        "    try:\n",
        "      Holder_address = burn['sender'] #sender가 Burn을 한 Address\n",
        "      if(Holder_address in zap_list):\n",
        "        continue\n",
        "      LP_amount = Decimal(burn['liquidity'])\n",
        "      LP_Holders[Holder_address] = LP_Holders[Holder_address] - LP_amount\n",
        "      if( LP_Holders[Holder_address] < 1E-17 ):\n",
        "        del LP_Holders[Holder_address]\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "      print(e)\n",
        "  #      print(\"Burn execution from non-existent address [translation by MJ]\")\n",
        "  #      print(\"Holder address = %s\" % Holder_address)\n",
        "  return LP_Holders\n",
        "\n",
        "def get_LP_stdev(LP_Holders):\n",
        "  total_LP_amount = 0\n",
        "  LP_ratio_dict = {}\n",
        "\n",
        "  #전체 LP amount 구하기\n",
        "  for LPtoken_amount in LP_Holders.values():\n",
        "    total_LP_amount = total_LP_amount + LPtoken_amount\n",
        "\n",
        "  #홀더 별 보유 비율 구하기\n",
        "  for address,LPtoken_amount in LP_Holders.items():\n",
        "    LP_ratio_dict[address] = (LPtoken_amount / total_LP_amount) * 100\n",
        "\n",
        "  #보유 비율에 대해서 평균계산\n",
        "  LP_avg = 100 / len(LP_Holders)\n",
        "\n",
        "  #보유 비율에 대한 분산, 표준편차 계산\n",
        "  LP_var =0\n",
        "  for ratio in LP_ratio_dict.values():\n",
        "    LP_var = LP_var + (ratio - Decimal(LP_avg))**2\n",
        "  LP_var = LP_var / len(LP_Holders)\n",
        "\n",
        "  LP_stdev = sqrt(LP_var)\n",
        "\n",
        "  return LP_stdev, LP_avg, total_LP_amount"
      ],
      "metadata": {
        "id": "YOcH2Mrha988"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import glob\n",
        "from pandas.core.accessor import delegate_names\n",
        "from pandas.core.frame import DataFrame\n",
        "import requests\n",
        "\n",
        "def createFolder(directory):\n",
        "    try:\n",
        "        if not os.path.exists(directory):\n",
        "            os.makedirs(directory)\n",
        "    except OSError:\n",
        "        print ('Error: Creating directory. ' +  directory)\n",
        "\n",
        "\n",
        "def split_csv(total_csv):\n",
        "    rows = pd.read_csv(total_csv,chunksize=5000)\n",
        "    file_count = 0\n",
        "    for i, chuck in enumerate(rows):\n",
        "        chuck.to_csv('./result/out{}.csv'.format(i),encoding='utf-8-sig',index=False)\n",
        "        file_count = file_count+1\n",
        "    return file_count\n",
        "\n",
        "\n",
        "def merge_csv():\n",
        "  input_file = r'./result/'\n",
        "  output_file = r'./result/result'\n",
        "\n",
        "  allFile_list = glob.glob(os.path.join(input_file, 'fout*')) # glob함수로 sales_로 시작하는 파일들을 모은다\n",
        "  allFile_list.sort()\n",
        "  for file in allFile_list:\n",
        "      output_file = output_file + file[-5]\n",
        "  output_file = output_file +'.csv'\n",
        "\n",
        "  all_Data = []\n",
        "  for file in allFile_list:\n",
        "    records = pd.read_csv(file).to_dict('records')\n",
        "    all_Data.extend(records)\n",
        "\n",
        "  DataFrame(all_Data).to_csv(output_file,encoding='utf-8-sig',index=False)\n",
        "  print(\"결과물 파일 : \" + output_file)"
      ],
      "metadata": {
        "id": "2gSlmG3MizkC"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.core.frame import DataFrame\n",
        "import pandas as pd\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from multiprocessing import Pool\n",
        "from multiprocessing import Process\n",
        "import datetime\n",
        "\n",
        "def switch_file(file_name):\n",
        "    global datas\n",
        "    datas = pd.read_csv(file_name).to_dict('records')\n",
        "\n",
        "\n",
        "'''\n",
        "pair_address = '0x49179a590b086ee09dacc5750cfdb312c0c73d10'\n",
        "mint_data_transaction[0]\n",
        "initial_timestamp\n",
        "last_timestamp\n",
        "active_period / (60*60*24*30)\n",
        "\n",
        "\n",
        "'''\n",
        "\n",
        "def get_feature(data):\n",
        "    try:\n",
        "        pair_address = data['id']\n",
        "\n",
        "        #TheGraph API를 이용해서 하나의 페어에 대한 쌍들을 전부 메모리에 올려놓고. 시작\n",
        "        mint_data_transaction = call_theGraph_mint(pair_address)\n",
        "        swap_data_transaction = call_theGraph_swap(pair_address)\n",
        "        burn_data_transaction = call_theGraph_burn(pair_address)\n",
        "\n",
        "        rugpull_timestamp, rugpull_change, is_rugpull, before_rugpull_Eth, after_rugpull_Eth,rugpull_method = get_rugpull_timestamp(mint_data_transaction,swap_data_transaction,burn_data_transaction,token_index(data))\n",
        "\n",
        "\n",
        "        #initial_Liquidity 의 이더와 토큰 구하기\n",
        "        initial_Liquidity_Eth , initial_Liquidity_Token = get_initial_Liquidity(data['token0.symbol'],mint_data_transaction)\n",
        "\n",
        "        # 각각의 count 구하기\n",
        "        mint_count = len(mint_data_transaction)\n",
        "        swap_count = len(swap_data_transaction)\n",
        "        burn_count = len(burn_data_transaction)\n",
        "\n",
        "        # Mint/Burn/Swap의 Active Period 상의 분포\n",
        "        initial_timestamp = int(mint_data_transaction[0]['timestamp'])\n",
        "        last_timestamp = get_last_timestamp(mint_data_transaction,swap_data_transaction,burn_data_transaction)\n",
        "        active_period = last_timestamp - initial_timestamp\n",
        "        mint_mean_period = int(get_mint_mean_period(mint_data_transaction,initial_timestamp))\n",
        "        swap_mean_period = int(get_swap_mean_period(swap_data_transaction,initial_timestamp))\n",
        "        burn_mean_period = int(get_burn_mean_period(burn_data_transaction,initial_timestamp))\n",
        "\n",
        "        #SwapIn/SwapOut 비율\n",
        "        swapIn,swapOut = swap_IO_rate(swap_data_transaction,token_index(data))\n",
        "\n",
        "\n",
        "        #rugpull 이 시작부터 끝날때까지 경과한 시간\n",
        "        rugpull_proceeding_time = int(rugpull_timestamp) - int(initial_timestamp)\n",
        "        if(is_rugpull == False):\n",
        "            rugpull_proceeding_time = 0\n",
        "            rugpull_method = ''\n",
        "            rugpull_timestamp = '0'\n",
        "            rugpull_change = ''\n",
        "\n",
        "\n",
        "        LP_Creator = mint_data_transaction[0]['to']\n",
        "        #mint/burn을 분석해서 해당 시점에 LP홀더들의 보유량을 dictionary로 만든다.\n",
        "        LP_Holders = calc_LPToken_Holders(mint_data_transaction,burn_data_transaction)\n",
        "        LP_stdev, LP_avg, total_LP_amount = get_LP_stdev(LP_Holders)\n",
        "        try:\n",
        "            LP_Creator_amount = LP_Holders[LP_Creator] #해당시점에 LP초기 제공자가 가지고 있는 양\n",
        "        except:\n",
        "            LP_Creator_amount = 0\n",
        "\n",
        "\n",
        "        #데이터 저장\n",
        "        data['initial_Liquidity_Eth'] = initial_Liquidity_Eth\n",
        "        data['initial_Liquidity_Token'] = initial_Liquidity_Token\n",
        "        data['last_transaction_timestamp'] = last_timestamp\n",
        "        data['last_transaction_date'] = datetime.datetime.fromtimestamp(int(last_timestamp)).strftime('%Y-%m-%d %H:%M:%S')\n",
        "        data['mint_count'] = mint_count\n",
        "        data['swap_count'] = swap_count\n",
        "        data['burn_count'] = burn_count\n",
        "        data['mint_mean_period'] = mint_mean_period\n",
        "        data['swap_mean_period'] = swap_mean_period\n",
        "        data['burn_mean_period'] = burn_mean_period\n",
        "        data['swapIn'] = swapIn\n",
        "        data['swapOut'] = swapOut\n",
        "        data['active_period'] = active_period\n",
        "        data['rugpull_method'] = rugpull_method\n",
        "        data['rugpull_timestamp'] = rugpull_timestamp\n",
        "        data['rugpull_timestamp_date'] = datetime.datetime.fromtimestamp(int(rugpull_timestamp)).strftime('%Y-%m-%d %H:%M:%S')\n",
        "        data['before_rugpull_Eth'] = before_rugpull_Eth\n",
        "        data['after_rugpull_Eth'] = after_rugpull_Eth\n",
        "        data['rugpull_change'] = rugpull_change\n",
        "        data['rugpull_proceeding_hour'] = str(rugpull_proceeding_time / 3600) + 'h'\n",
        "        data['LP_Creator_amount'] = LP_Creator_amount\n",
        "        data['LP_Creator_address'] = LP_Creator\n",
        "        data['LP_avg'] = LP_avg\n",
        "        data['LP_stdev'] = LP_stdev\n",
        "        data['total_LP_amount'] = total_LP_amount\n",
        "        data['is_rugpull'] = is_rugpull\n",
        "\n",
        "        return data\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        return -1\n",
        "\n",
        "\n",
        "\n",
        "if __name__=='__main__':\n",
        "    createFolder('./result')\n",
        "    file_name = './minitemp.csv'\n",
        "    file_count = split_csv(file_name)\n",
        "    out_list = []\n",
        "    out_list = list(input('입력(공백단위) : ').split())\n",
        "\n",
        "    for i in out_list:         #하나의 파일 단위로 Creator Address 불러오고, 해당 초기 유동성풀 이더값 구해온다.\n",
        "        file_name = './result/out{}.csv'.format(i)\n",
        "        switch_file(file_name)\n",
        "        datas_len = len(datas)\n",
        "        try:\n",
        "            p = Pool(4)\n",
        "            count = 0\n",
        "            result = []\n",
        "            for ret in p.imap(get_feature,datas):\n",
        "                if(ret == -1):\n",
        "                    count = count+1\n",
        "                    continue\n",
        "                count = count+1\n",
        "                result.append(ret)\n",
        "                if(count % 200 == 0):\n",
        "                    print(\"Process Rate : {}/{} {}%\".format(count,datas_len,int((count/datas_len)*100)))\n",
        "            p.close()\n",
        "            p.join()\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "        print('===================================   finish    =========================================')\n",
        "        time.sleep(5)\n",
        "\n",
        "        df = pd.DataFrame(result)\n",
        "        file_name = './result/fout{}.csv'.format(i)\n",
        "        df.to_csv(file_name,encoding='utf-8-sig',index=False)\n",
        "        print(file_name + ' complete')\n",
        "    merge_csv()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "PK3FHpD7i6Yq",
        "outputId": "33e8b442-608b-4fbe-d142-66662a1a0de6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력(공백단위) : 0\n",
            "local variable 'LP_amount' referenced before assignment\n",
            "local variable 'LP_amount' referenced before assignment\n",
            "local variable 'LP_amount' referenced before assignment\n",
            "local variable 'LP_amount' referenced before assignment\n",
            "===================================   finish    =========================================\n",
            "./result/fout0.csv complete\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "EmptyDataError",
          "evalue": "No columns to parse from file",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mEmptyDataError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-c07d910b3a0a>\u001b[0m in \u001b[0;36m<cell line: 110>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8-sig'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' complete'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m     \u001b[0mmerge_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-19-40302f03e7db>\u001b[0m in \u001b[0;36mmerge_csv\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m   \u001b[0mall_Data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mallFile_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mrecords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'records'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0mall_Data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1678\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1679\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1680\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1681\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;31m# Fail here loudly instead of in cython after reading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mimport_optional_dependency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pyarrow\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mEmptyDataError\u001b[0m: No columns to parse from file"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tempdf = pd.read_csv(\"/content/result/out0.csv\")"
      ],
      "metadata": {
        "id": "RFYNc82qjMye"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tempdf.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ExRo8r1kCKe",
        "outputId": "b73d36b0-b5e3-4701-937f-4467941080ea"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4 entries, 0 to 3\n",
            "Data columns (total 31 columns):\n",
            " #   Column                  Non-Null Count  Dtype  \n",
            "---  ------                  --------------  -----  \n",
            " 0   createdAtBlockNumber    4 non-null      int64  \n",
            " 1   createdAtTimestamp      4 non-null      object \n",
            " 2   id                      4 non-null      object \n",
            " 3   reserve0                4 non-null      float64\n",
            " 4   reserve1                4 non-null      float64\n",
            " 5   reserveETH              4 non-null      float64\n",
            " 6   reserveUSD              4 non-null      float64\n",
            " 7   totalSupply             4 non-null      float64\n",
            " 8   txCount                 4 non-null      int64  \n",
            " 9   reserve00               4 non-null      float64\n",
            " 10  reserve11               4 non-null      float64\n",
            " 11  token0.id               4 non-null      object \n",
            " 12  token0.name             4 non-null      object \n",
            " 13  token0.symbol           4 non-null      object \n",
            " 14  token0.totalLiquidity   4 non-null      float64\n",
            " 15  token0.txCount          4 non-null      int64  \n",
            " 16  token1.id               4 non-null      object \n",
            " 17  token1.name             4 non-null      object \n",
            " 18  token1.symbol           4 non-null      object \n",
            " 19  token1.totalLiquidity   4 non-null      float64\n",
            " 20  token1.txCount          4 non-null      int64  \n",
            " 21  token00.id              4 non-null      object \n",
            " 22  token00.name            4 non-null      object \n",
            " 23  token00.symbol          4 non-null      object \n",
            " 24  token00.totalLiquidity  4 non-null      float64\n",
            " 25  token00.txCount         4 non-null      int64  \n",
            " 26  token11.id              4 non-null      object \n",
            " 27  token11.name            4 non-null      object \n",
            " 28  token11.symbol          4 non-null      object \n",
            " 29  token11.totalLiquidity  4 non-null      float64\n",
            " 30  token11.txCount         4 non-null      int64  \n",
            "dtypes: float64(11), int64(6), object(14)\n",
            "memory usage: 1.1+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tempdf1 = pd.read_csv(\"/content/result/fout0.csv\")\n",
        "tempdf1.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "E69HVsiTkD5k",
        "outputId": "0523e78b-98f7-462b-85e3-87787c8edec3"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "EmptyDataError",
          "evalue": "No columns to parse from file",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mEmptyDataError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-841a5029f14e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtempdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/result/fout0.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtempdf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1678\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1679\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1680\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1681\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;31m# Fail here loudly instead of in cython after reading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mimport_optional_dependency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pyarrow\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mEmptyDataError\u001b[0m: No columns to parse from file"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jGzooPNOkYbw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}